---
title: Pythonçˆ¬è™«å…¥é—¨
date: 2022-01-04 13:19:14
tags: python
---
#### æ— èŠçš„å‰è¨€
å‰å‡ å¤©æºœé˜¿æ¾æœ‰ç‚¹å¤šï¼Œå¿ƒè¡€æ¥æ½®æƒ³åˆ°ä¸€ä¸ªæœ‰æ„æ€çš„ç‚’ä½œç‚¹å­ã€‚ä½†è¦å®ç°éœ€è¦å‡ åä¸ªè§†é¢‘å°é¢ï¼Œè™½ç„¶F12æ‰¾å›¾ç‰‡ç›´é“¾å¾ˆå®¹æ˜“ï¼Œä½†ä¸€ä¸ªä¸€ä¸ªä¸‹å®åœ¨æœ‰ç‚¹éº»çƒ¦ï¼Œåˆšå¥½åœ¨å­¦pythonçš„requestsåº“ï¼Œå°±æƒ³å†™ä¸ªçˆ¬è™«å…¨çˆ¬ä¸‹æ¥ã€‚

## çˆ¬è™«åŸºæœ¬æ€è·¯
çˆ¬è™«æœ‰å¾ˆå¤šå†™æ³•ï¼ŒJavaï¼ŒJavaScriptï¼ŒPythonéƒ½å¯ä»¥ï¼Œä½†pythonçš„requestsåº“å¾ˆæ–¹ä¾¿ï¼Œæœ€å¸¸ç”¨çš„æ˜æ˜¾æ˜¯pythonçˆ¬è™«ã€‚åœ¨å…·ä½“ä»£ç å®ç°å±‚é¢ï¼Œå¤§å¤šæ•°çˆ¬è™«éƒ½æœ‰éå¸¸ç›¸ä¼¼çš„ç»“æ„:
1. åˆ†æç½‘é¡µç»“æ„ï¼Œæ‰¾å‡ºæœ‰è§„å¾‹çš„æ¥å£
2. åˆ©ç”¨requestsåº“å‘èµ·è¯·æ±‚

è¿™ä¸¤ä¸ªè¿‡ç¨‹æ˜¯é€šç”¨çš„ï¼Œä½†å¯¹ä¸‹é¢çš„æ“ä½œï¼Œé™æ€ç½‘é¡µä¸åŠ¨æ€ç½‘é¡µä¸åŒ:

å¯¹é™æ€ç½‘é¡µï¼Œåˆ©ç”¨beautifulsoupåº“è§£æé¡µé¢æŠ“å–å†…å®¹
å¯¹åŠ¨æ€ç½‘é¡µï¼Œåˆ©ç”¨jsonåº“è§£æå¾—åˆ°çš„jsonæ•°æ®
é™æ€ç½‘é¡µå³åœ¨æµè§ˆç½‘é¡µè¿‡ç¨‹ä¸­æ²¡æœ‰æµè§ˆå™¨ä¸æœåŠ¡å™¨äº¤äº’çš„ç½‘é¡µï¼Œæ­¤æ—¶Ctrl+uä¸F12å®¡æŸ¥å…ƒç´ å¾—åˆ°çš„æºç ç›¸åŒï¼Œç›´æ¥å‘èµ·è¯·æ±‚ï¼Œå†ç”¨bs4åº“è§£æç½‘é¡µæºç å†…å®¹å³å¯.

bs4åº“ä¹Ÿæ˜¯éå¸¸å¥½ç”¨çš„pythonè§£æåº“ï¼Œå¯¹äºçˆ¬è™«ï¼Œæ‰¾åˆ°éœ€è¦çˆ¬å–éƒ¨åˆ†çš„ç½‘é¡µæºç ï¼Œç„¶åæ³¨æ„å…¶å‘¨å›´å”¯ä¸€çš„å…ƒç´ åæˆ–classåå†ç”¨find_all()å…·ä½“è§£æå³å¯ã€‚

ä¾‹å¦‚:
```python
def find(url):
    web = requests.get(url, headers=headers)
    # å‘èµ·è¯·æ±‚
    html = web.content.decode("utf-8")
    # å–å¾—ç¶²é å…§å®¹
    soup = BeautifulSoup(html, "lxml")
    # è½‰æ›æˆæ¨™ç±¤æ¨¹ æ‰¾é é¢å†…DOMåƒæ•¸
    lis = soup.find_all('li', class_="small-item fakeDanmu-item")
    # classä¸ºpythonä¿ç•™å­—ï¼Œæ•…éœ€è¦ç”¨class_
    # small-item fakeDanmu-itemä¸ºé¡µé¢å†…å”¯ä¸€çš„classå
    url0 = lis[1].a.img['src']
    img_url = 'http://'+url0
    return img_url
```

ä½†é™æ€ç½‘é¡µæ²¡æœ‰ç½‘é¡µäº¤äº’ï¼Œä¸”éœ€è¦ä¸€æ¬¡æ€§åŠ è½½å‡ºæ‰€æœ‰å†…å®¹ï¼Œè¾ƒä¸ºä¸ä¾¿ã€‚åŠ¨æ€ç½‘é¡µåˆ™æ²¡æœ‰è¿™ç§åŠ£åŠ¿ï¼ŒåŠ¨æ€ç½‘é¡µåˆ©ç”¨Ajaxä¸æ–­å‘èµ·å¯¹æœåŠ¡å™¨çš„è¯·æ±‚ï¼Œæ— éœ€åˆ·æ–°é¡µé¢å³å¯å®Œæˆå†…å®¹æ›´æ–°ã€‚

## å®æˆ˜:çˆ¬å–Bç«™ä¸ªäººä¸»é¡µè§†é¢‘å°é¢
æœ¬æ¥å‡†å¤‡ç”¨bs4è§£æé¡µé¢ï¼Œç»“æœå‘ç°è¯·æ±‚åæ‰¾ä¸åˆ°å†…å®¹ğŸ˜“ï¼Œæ‰å‘ç°Bç«™ä¸ªäººä¸»é¡µæ˜¯AjaxåŠ¨æ€ç½‘é¡µ

ä¸»é¡µé‡Œçš„æŠ•ç¨¿åˆ—è¡¨æ˜¯é€šè¿‡ä¸€ä¸ªXHR(å³Ajaxçš„jsonè¯·æ±‚)è·å–çš„ï¼Œå› æ­¤åŠ¨æ€é¡µé¢çˆ¬å–åè€Œæ›´ç®€å•ï¼Œåªéœ€è¦åˆ†æé¡µé¢æ‰¾åˆ°å¯¹åº”çš„apiï¼Œå¯¹è¿™ä¸ªapiå‘èµ·è¯·æ±‚è·å–jsonæ•°æ®ï¼Œå†ç”¨jsonåº“è½¬æˆpythonå­—å…¸ï¼Œå°±èƒ½è½»æ¾æ‰¾åˆ°å°é¢ç›´é“¾urlã€‚

```python
def find_url(url0, num0):
    web = requests.get(url0)
    data = json.loads(web.text)
    # å¤„ç†jsonæ•°æ®
    pic_url = data["data"]["list"]["vlist"][num0]["pic"]
    return pic_url
```

ä¸Šé¢è¿™ä¸ªå‡½æ•°çš„å‚æ•°num0ä¸ºå˜é‡ï¼Œå¯ä»¥åˆ©ç”¨è¿™ä¸ªå¾ªç¯çˆ¬å–å†…å®¹ï¼Œè¿™æ ·å°±å–å¾—äº†å°é¢å›¾ç‰‡ç›´é“¾ï¼Œä¸‹ä¸€æ­¥æ˜¯å°†å…¶ä¸‹è½½è‡³æŒ‡å®šç›®å½•

```python
def download(url1, download_num):
    jpg = requests.get(url1, headers=headers)
    # è«‹æ±‚é é¢
    f = open("azusa" + str(download_num) + ".jpg", 'wb')
    # æ–°å»ºä¸€ä¸ª.jpgæ–‡ä»¶ï¼Œæ–‡ä»¶åä¸ºazusa+æ•°å­—(strå‡½æ•°å°†æ•°ç»„è½¬ä¸ºå­—ç¬¦ä¸²)
    f.write(jpg.content)
    # å†™å…¥é¡µé¢å†…å®¹
    f.close()
    print('Pic saved!')

```

å†åœ¨ä¸»å‡½æ•°é‡Œå†™å…¥å¾ªç¯è°ƒç”¨è¿™ä¸¤ä¸ªå‡½æ•°å³å¯ï¼Œå®Œæ•´çˆ¬è™«æºç å¦‚ä¸‹:

```python
# -*- coding:utf-8 -*-
# MyfirstPyScript
# coded by Yo1uk0
 
import requests
# from bs4 import BeautifulSoup
import json
 
path = "/mnt/c/workplace"
# å†™å…¥æ–‡ä»¶çš„ç›®å½•
url = "https://api.bilibili.com/x/space/arc/search?mid=231590&ps=30&tid=0&pn=1&keyword=&order=click&jsonp=jsonp"
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '
                  'Chrome/96.0.4664.110 Safari/537.36',
    'referer': 'https://space.bilibili.com/231590/video'}
# æœ‰äº›é¡µé¢æœ‰åçˆ¬æªæ–½ï¼ŒåŠ æ­£å¸¸æµè§ˆå™¨çš„è¯·æ±‚å¤´å¯ä»¥ä¸€å®šç¨‹åº¦ååçˆ¬
 
 
def find_url(url0, num0):
    web = requests.get(url0,headers=headers)
    data = json.loads(web.text)
    pic_url = data["data"]["list"]["vlist"][num0]["pic"]
    return pic_url
 
 
def download(url1, download_num):
    jpg = requests.get(url1, headers=headers)
    f = open("azusa" + str(download_num) + ".jpg", 'wb')
    f.write(jpg.content)
    f.close()
    print('Pic saved!')
 
 
def main():
    for num in range(30):
        url1 = find_url(url, num)
        download(url1, num)
    print('all pics are saved!')
 
 
if __name__ == '__main__':
    main()
```
![img](https://files.catbox.moe/3xpren.jpg)
å¤§åŠŸå‘Šæˆã€‚